{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "technical_analysis_for_stock_price_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eMwOPI0J0j1F",
        "P_Pq0YrFWiGR"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjanshrestha123/Technical-Analysis-For-Stock-Price-Prediction/blob/master/technical_analysis_for_stock_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugEzjcGDWiGB"
      },
      "source": [
        "# Technical Analysis for Stock Price Prediction #\n",
        "\n",
        "\n",
        "Reference (Citation): https://github.com/krishnaik06/Stock-MArket-Forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDwgSyOavxyB"
      },
      "source": [
        "**Todo:**\n",
        "1. Create different models and compare accuracy\n",
        "2. Cross validation and hyperparameter tuning\n",
        "4. Predict Trend\n",
        "5. Format Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "hu2FrTURWiGF"
      },
      "source": [
        "###Import and Packages###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "1Pp5y4R9WiGF",
        "outputId": "eaca23fc-4f97-4b83-be84-3a8cb4cdec18"
      },
      "source": [
        "# For dealing with dataframe\n",
        "import pandas as pd\n",
        "\n",
        "# For dealing with np array\n",
        "import numpy as np\n",
        "\n",
        "# For calling yahoo finance to get stock price \n",
        "import pandas_datareader as pdr\n",
        "import datetime as dt\n",
        "from datetime import timedelta\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For model\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "# For upgrading pandas datareader module\n",
        "!pip install --upgrade pandas_datareader"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas_datareader in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Collecting pandas_datareader\n",
            "  Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas_datareader) (2.23.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas_datareader) (4.2.6)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from pandas_datareader) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas_datareader) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas_datareader) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas_datareader) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas_datareader) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas_datareader) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas_datareader) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas_datareader) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas_datareader) (2021.10.8)\n",
            "Installing collected packages: pandas-datareader\n",
            "  Attempting uninstall: pandas-datareader\n",
            "    Found existing installation: pandas-datareader 0.9.0\n",
            "    Uninstalling pandas-datareader-0.9.0:\n",
            "      Successfully uninstalled pandas-datareader-0.9.0\n",
            "Successfully installed pandas-datareader-0.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas_datareader"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBmRdGxvvccA"
      },
      "source": [
        "### Model Properties ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skV3nY6pv-kA"
      },
      "source": [
        "# Yahoo Finance API Properties\n",
        "NUMBER_OF_YEARS_TO_FETCH_PRICE_DATA = 30\n",
        "\n",
        "# Dataset Properties\n",
        "DATE = 'Date'\n",
        "CLOSE = 'Close'\n",
        "VOLUME = 'Volume'\n",
        "\n",
        "# Stock Properties \n",
        "STOCK_TICKER = 'TSLA' # Stock ticker name to run the model\n",
        "\n",
        "# Hyperparameters\n",
        "NUMBER_OF_DAYS_FOR_PRICE_PREDICTION = 100\n",
        "NUMBER_OF_DAYS_TO_PREDICT = 10\n",
        "NUMBER_OF_EPOCHS = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "A1R9zQJgWiGH"
      },
      "source": [
        "##  1. Extract Raw data and Dataset Creation ##\n",
        "Calling Yahoo Finance API to extract data for last 7 years from current date and convert it to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHpyMSK1WiGH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "18dcdaa6-bff8-4617-a29e-849994e10895"
      },
      "source": [
        "# Getting start and end date for stock data\n",
        "end_date = dt.date.today()\n",
        "start_date = end_date - timedelta(days=NUMBER_OF_YEARS_TO_FETCH_PRICE_DATA * 365)  # Getting start date as last 'n' number of years from now\n",
        "\n",
        "# Calling Yahoo Finance API for last 7 years of stock data \n",
        "df = pdr.get_data_yahoo(STOCK_TICKER, start = start_date, end = end_date)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RemoteDataError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteDataError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2e6b030bc8db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Calling Yahoo Finance API for last 7 years of stock data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_yahoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOCK_TICKER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_datareader/data.py\u001b[0m in \u001b[0;36mget_data_yahoo\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mEnigmaReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_quote_av\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mAVQuotesReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_datareader/base.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# If a single symbol, (e.g., 'GOOG')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_one_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;31m# Or multiple symbols, (e.g., ['GOOG', 'AAPL', 'MSFT'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_datareader/yahoo/daily.py\u001b[0m in \u001b[0;36m_read_one_data\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dispatcher\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stores\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HistoricalPriceStore\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"No data fetched for symbol {} using {}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_datareader/base.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(self, url, params, headers)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\nResponse Text:\\n{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_response_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRemoteDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_crumb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRemoteDataError\u001b[0m: Unable to read URL: https://finance.yahoo.com/quote/TSLA/history?period1=690955200&period2=1637121599&interval=1d&frequency=1d&filter=history\nResponse Text:\nb'<!DOCTYPE html>\\n  <html lang=\"en-us\"><head>\\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\\n      <meta charset=\"utf-8\">\\n      <title>Yahoo</title>\\n      <meta name=\"viewport\" content=\"width=device-width,initial-scale=1,minimal-ui\">\\n      <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\\n      <style>\\n  html {\\n      height: 100%;\\n  }\\n  body {\\n      background: #fafafc url(https://s.yimg.com/nn/img/sad-panda-201402200631.png) 50% 50%;\\n      background-size: cover;\\n      height: 100%;\\n      text-align: center;\\n      font: 300 18px \"helvetica neue\", helvetica, verdana, tahoma, arial, sans-serif;\\n  }\\n  table {\\n      height: 100%;\\n      width: 100%;\\n      table-layout: fixed;\\n      border-collapse: collapse;\\n      border-spacing: 0;\\n      border: none;\\n  }\\n  h1 {\\n      font-size: 42px;\\n      font-weight: 400;\\n      color: #400090;\\n  }\\n  p {\\n      color: #1A1A1A;\\n  }\\n  #message-1 {\\n      font-weight: bold;\\n      margin: 0;\\n  }\\n  #message-2 {\\n      display: inline-block;\\n      *display: inline;\\n      zoom: 1;\\n      max-width: 17em;\\n      _width: 17em;\\n  }\\n      </style>\\n  <script>\\n    document.write(\\'<img src=\"//geo.yahoo.com/b?s=1197757129&t=\\'+new Date().getTime()+\\'&src=aws&err_url=\\'+encodeURIComponent(document.URL)+\\'&err=%<pssc>&test=\\'+encodeURIComponent(\\'%<{Bucket}cqh[:200]>\\')+\\'\" width=\"0px\" height=\"0px\"/>\\');var beacon = new Image();beacon.src=\"//bcn.fp.yahoo.com/p?s=1197757129&t=\"+ne..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cr5-MD7WiGK"
      },
      "source": [
        "# Visualizing Dataset\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJfJ-3Xj23Jo"
      },
      "source": [
        "# Visualizing the shape of Dataset\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enQKrnCPy-B-"
      },
      "source": [
        "## 2. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwkCH-rOWiGL"
      },
      "source": [
        "# Plotting the graph visualizing price change with date\n",
        "df.plot(y=[CLOSE],figsize=(15,10), ylabel='Stock Price')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48IzLP-D2i4d"
      },
      "source": [
        "## 3. Feature Engineering ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFq26cgE3PVh"
      },
      "source": [
        "model_df = df.reset_index()[CLOSE]\n",
        "model_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Nc5awN9oWiGM"
      },
      "source": [
        "## 4. Split data into train and test ##\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN9vBhs842tn"
      },
      "source": [
        "### I. Splitting Data for LSTM ###\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbDxyb0o4708"
      },
      "source": [
        "# Tranforming value to 0-1 since lstm are sensitive to the scale of the data\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "model_df_lstm = scaler.fit_transform(np.array(model_df).reshape(-1,1))\n",
        "model_df_lstm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtGMRMIPWiGN"
      },
      "source": [
        "# Split the first 70% of data to training set and last 30% to testing set since our dataset is time-series data\n",
        "train_index_lstm = 0.7 * model_df_lstm.shape[0]\n",
        "train_data_lstm = model_df_lstm[:int(train_index_lstm)]\n",
        "test_data_lstm = model_df_lstm[int(train_index_lstm):]\n",
        "test_data_lstm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7aKPHG1WiGN"
      },
      "source": [
        "# Function to create dataset into feature and target\n",
        "def create_dataset_lstm(dataset, time_step=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset) - time_step-1):\n",
        "        a = dataset[i:(i+time_step), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i+time_step, 0])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZLg7CC-WiGO"
      },
      "source": [
        "# Creating dataset for training and testing\n",
        "X_train_lstm, y_train_lstm = create_dataset_lstm(train_data_lstm, NUMBER_OF_DAYS_FOR_PRICE_PREDICTION)\n",
        "X_test_lstm, y_test_lstm = create_dataset_lstm(test_data_lstm, NUMBER_OF_DAYS_FOR_PRICE_PREDICTION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dr5CKhl7DIP"
      },
      "source": [
        "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
        "X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], 1)\n",
        "X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], 1)\n",
        "\n",
        "print('Training Shape: ', X_train_lstm.shape)\n",
        "print('Testing Shape: ', X_test_lstm.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pcMPECE8UsG"
      },
      "source": [
        "### II. Splitting Data for other Models ###\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeFvgU9B8bLd"
      },
      "source": [
        "# Split the first 70% of data to training set and last 30% to testing set since our dataset is time-series data\n",
        "train_index = 0.7 * model_df.shape[0]\n",
        "train_data = list(model_df[:int(train_index)])\n",
        "test_data = list(model_df[int(train_index):])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_BOu-nn8xjN"
      },
      "source": [
        "# Function to create dataset into feature and target\n",
        "def create_dataset(dataset, time_step=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset) - time_step-1):\n",
        "        a = dataset[i:(i+time_step)]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i+time_step])\n",
        "    return np.array(dataX), np.array(dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SEWvua_8ycf"
      },
      "source": [
        "# Creating dataset for training and testing\n",
        "X_train, y_train = create_dataset(train_data, NUMBER_OF_DAYS_FOR_PRICE_PREDICTION)\n",
        "X_test, y_test= create_dataset(test_data, NUMBER_OF_DAYS_FOR_PRICE_PREDICTION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D7o9k_LWiGO"
      },
      "source": [
        "## 5. Create and Train Different Models##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwOPI0J0j1F"
      },
      "source": [
        "### I. Create and Train LSTM Model ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZIbcPD5WiGP"
      },
      "source": [
        "# Create Stacked LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(NUMBER_OF_DAYS_FOR_PRICE_PREDICTION,1)))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "WjMEXdjbWiGP"
      },
      "source": [
        "model.fit(X_train_lstm, y_train_lstm, validation_data=(X_test_lstm, y_test_lstm), epochs=NUMBER_OF_EPOCHS, batch_size=64, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw2fwKtu0-3L"
      },
      "source": [
        "### II. Create and Train Linear Regression ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGbYDtCp1DMn"
      },
      "source": [
        "# Create and Train Linear Regression Model\n",
        "reg = LinearRegression().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8HuutlyVBfa"
      },
      "source": [
        "### III. Create and Train Decision Tree Regression ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuSpHA5BVBp7"
      },
      "source": [
        "# Create and Train Decision Tree Model\n",
        "d_tree = DecisionTreeRegressor().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJzdAQZDV-1H"
      },
      "source": [
        "### IV. Create and Train KNN Regression \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk1mJeBpV86I"
      },
      "source": [
        "knn = KNeighborsRegressor().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPchvgvfWiGQ"
      },
      "source": [
        "## 6. Evaluate the Model##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52sZAIDZCc_4"
      },
      "source": [
        "# Shift train predictions for plotting\n",
        "def plot_graph(model_df, model, X_train, X_test):\n",
        "  # Making prediction for train and test set for plotting\n",
        "  train_predict = model.predict(X_train)\n",
        "  test_predict = model.predict(X_test)\n",
        "\n",
        "  look_back = NUMBER_OF_DAYS_FOR_PRICE_PREDICTION\n",
        "  train_predict_plot = [ np.nan for i in range(len(model_df))]\n",
        "  train_predict_plot[look_back:len(train_predict) + look_back] = np.array(train_predict)\n",
        "\n",
        "  # Shift test predictions for plotting\n",
        "  test_predict_plot = [ np.nan for i in range(len(model_df))]\n",
        "  test_predict_plot[len(train_predict) + (look_back*2)+1:len(model_df)-1] = list(test_predict)\n",
        "\n",
        "  # Plot baseline and predictions\n",
        "  plt.plot(model_df)\n",
        "  plt.plot(train_predict_plot)\n",
        "  plt.plot(test_predict_plot)\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwsSskqY1cda"
      },
      "source": [
        "### I. Evaluate LSTM ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHh5puNmWiGQ"
      },
      "source": [
        "# Predict and check performance metrics\n",
        "train_predict_lstm = model.predict(X_train_lstm)\n",
        "test_predict_lstm = model.predict(X_test_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdI_nTR1WiGQ"
      },
      "source": [
        "# Transform back to original form\n",
        "train_predict_lstm = scaler.inverse_transform(train_predict_lstm)\n",
        "test_predict_lstm = scaler.inverse_transform(test_predict_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-ESRiWhWiGR"
      },
      "source": [
        "# Test Data RMSE\n",
        "rmse_lstm = math.sqrt(mean_squared_error(y_test_lstm, test_predict_lstm))\n",
        "rmse_lstm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36uh04ehWiGR"
      },
      "source": [
        "# Shift train predictions for plotting\n",
        "look_back = NUMBER_OF_DAYS_FOR_PRICE_PREDICTION\n",
        "train_predict_plot = np.empty_like(model_df_lstm)\n",
        "train_predict_plot[:, :] = np.nan\n",
        "train_predict_plot[look_back:len(train_predict_lstm) + look_back, :] = train_predict_lstm\n",
        "\n",
        "# Shift test predictions for plotting\n",
        "test_predict_plot = np.empty_like(model_df_lstm)\n",
        "test_predict_plot[:, :] = np.nan\n",
        "test_predict_plot[len(train_predict_lstm) + (look_back*2)+1:len(model_df_lstm)-1, :] = test_predict_lstm\n",
        "\n",
        "# Plot baseline and predictions\n",
        "plt.plot(scaler.inverse_transform(model_df_lstm))\n",
        "plt.plot(train_predict_plot)\n",
        "plt.plot(test_predict_plot)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU7-WKgRArkO"
      },
      "source": [
        "### II. Evaluate Linear Regression ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3xe581CkHa3"
      },
      "source": [
        "# Test Data RMSE\n",
        "rmse_reg = math.sqrt(mean_squared_error(reg.predict(X_test), y_test))\n",
        "rmse_reg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbHW0pDYWtUE"
      },
      "source": [
        "# Plot train and test prediction in graph\n",
        "plot_graph(model_df, reg, X_train, X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkNzeDf1Ytm8"
      },
      "source": [
        "### III. Evaluate Decision Tree Regression ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MJPzHRfYtyf"
      },
      "source": [
        "# Test Data RMSE\n",
        "rmse_tree = math.sqrt(mean_squared_error(d_tree.predict(X_test), y_test))\n",
        "rmse_tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr91A3PtYt28"
      },
      "source": [
        "# Plot train and test prediction in graph\n",
        "plot_graph(model_df, d_tree, X_train, X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygeA4531Yt9c"
      },
      "source": [
        "### IV. Evaluate KNN Regression ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_LXww9kYuEQ"
      },
      "source": [
        "# Test Data RMSE\n",
        "rmse_knn = math.sqrt(mean_squared_error(knn.predict(X_test), y_test))\n",
        "rmse_knn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7hYKhtuYuGn"
      },
      "source": [
        "# Plot train and test prediction in graph\n",
        "plot_graph(model_df, d_tree, X_train, X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Pq0YrFWiGR"
      },
      "source": [
        "## 8. Predict Stock Market movement Trend for Next 30 Days Using Best Model ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1OwrbCMnT3w"
      },
      "source": [
        "# For LSTM\n",
        "lastest_data_index = len(test_data_lstm) - NUMBER_OF_DAYS_FOR_PRICE_PREDICTION\n",
        "x_input=test_data_lstm[lastest_data_index:].reshape(1,-1)\n",
        "\n",
        "temp_input=list(x_input)\n",
        "temp_input=temp_input[0].tolist()\n",
        "\n",
        "# demonstrate prediction for next n days\n",
        "lst_output=[]\n",
        "n_steps=NUMBER_OF_DAYS_FOR_PRICE_PREDICTION\n",
        "i=0\n",
        "while(i<NUMBER_OF_DAYS_TO_PREDICT):\n",
        "    \n",
        "    if(len(temp_input)>NUMBER_OF_DAYS_FOR_PRICE_PREDICTION):\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        x_input=x_input.reshape(1,-1)\n",
        "        x_input = x_input.reshape((1, n_steps, 1))\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        temp_input=temp_input[1:]\n",
        "        lst_output.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps,1))\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        lst_output.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "\n",
        "day_new=np.arange(1,NUMBER_OF_DAYS_FOR_PRICE_PREDICTION + 1)\n",
        "day_pred=np.arange(NUMBER_OF_DAYS_FOR_PRICE_PREDICTION + 1, NUMBER_OF_DAYS_FOR_PRICE_PREDICTION + NUMBER_OF_DAYS_TO_PREDICT + 1)\n",
        "\n",
        "lastest_model_df_index = len(model_df_lstm) - NUMBER_OF_DAYS_FOR_PRICE_PREDICTION\n",
        "\n",
        "df3=model_df_lstm.tolist()\n",
        "df3.extend(lst_output)\n",
        "df3=scaler.inverse_transform(df3).tolist()\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(df3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IBGbu6HpR5o"
      },
      "source": [
        "# For other model\n",
        "lastest_data_index = len(test_data) - NUMBER_OF_DAYS_FOR_PRICE_PREDICTION\n",
        "x_input=test_data[lastest_data_index:]\n",
        "\n",
        "temp_input=list(x_input)\n",
        "temp_input=[temp_input[0]]\n",
        "\n",
        "# demonstrate prediction for next n days\n",
        "lst_output = []\n",
        "last_n_days_data = test_data[lastest_data_index : ]\n",
        "next_day = None\n",
        "for day in range(NUMBER_OF_DAYS_TO_PREDICT):\n",
        "  if next_day is not None:\n",
        "    last_n_days_data = last_n_days_data[1:]\n",
        "    last_n_days_data.append(next_day)\n",
        "  next_day = reg.predict([last_n_days_data])[0]\n",
        "  lst_output.append(next_day)\n",
        "\n",
        "day_new=np.arange(1,NUMBER_OF_DAYS_FOR_PRICE_PREDICTION + 2)\n",
        "day_pred=np.arange(NUMBER_OF_DAYS_FOR_PRICE_PREDICTION + 1, NUMBER_OF_DAYS_FOR_PRICE_PREDICTION + NUMBER_OF_DAYS_TO_PREDICT + 1)\n",
        "\n",
        "lastest_model_df_index = len(model_df) - NUMBER_OF_DAYS_FOR_PRICE_PREDICTION\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "last_n_days = list(model_df[lastest_model_df_index:])\n",
        "last_n_days.append(lst_output[0])\n",
        "\n",
        "plt.plot(day_new,last_n_days)\n",
        "plt.plot(day_pred,lst_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkfikdF2yytG"
      },
      "source": [
        "model_df.iloc[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT14tX6rUkAI"
      },
      "source": [
        "## 9. Predict Stock Price for Next Day Using Best Model ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPgs3QQVneW5"
      },
      "source": [
        "# Displaying next day stock closing price for LSTM\n",
        "print('Stock Closing Price for next day: ', scaler.inverse_transform(lst_output)[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99-pJ1GWqsMf"
      },
      "source": [
        "# Next day price using other model\n",
        "last_n_days_data=test_data[len(test_data) - NUMBER_OF_DAYS_FOR_PRICE_PREDICTION:]\n",
        "next_day = reg.predict([last_n_days_data])[0]\n",
        "next_day"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLwWZYZMs_Fl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}